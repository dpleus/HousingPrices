{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Training File\n",
    "df_train=pd.read_csv(\"train.csv\")\n",
    "df_train[\"source\"]=\"Train\"\n",
    "\n",
    "#Read Test File\n",
    "df_test=pd.read_csv(\"test.csv\")\n",
    "df_test[\"source\"]=\"Test\"\n",
    "\n",
    "#Concat Dataset and split to X and Y\n",
    "df=pd.concat([df_test,df_train], axis=0)\n",
    "X=df.drop(\"SalePrice\",axis=1)\n",
    "y=df[\"SalePrice\"]\n",
    "\n",
    "#Save source as series and drop from DF\n",
    "source=df[\"source\"]\n",
    "df.drop(\"source\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering: Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining categorical and numerical variables\n",
    "num_cols=X.columns.values[(X.dtypes==\"int64\")|(X.dtypes==\"float64\")]\n",
    "cat_cols=X.columns.values[X.dtypes==\"object\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in cat_cols:\n",
    "    dummies=pd.get_dummies(X[each])\n",
    "    #dummies=dummies[1:]\n",
    "    X=pd.concat([X,dummies],axis=1)\n",
    "    X.drop(each,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "for each in X.columns.values:\n",
    "    #X[each]=X[each].fillna(np.median(X[each]))\n",
    "    X[each]=X[each].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>ConLw</th>\n",
       "      <th>New</th>\n",
       "      <th>Oth</th>\n",
       "      <th>WD</th>\n",
       "      <th>Grvl</th>\n",
       "      <th>Pave</th>\n",
       "      <th>AllPub</th>\n",
       "      <th>NoSeWa</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1159.581706</td>\n",
       "      <td>336.483727</td>\n",
       "      <td>2.602261</td>\n",
       "      <td>2.860226</td>\n",
       "      <td>441.272011</td>\n",
       "      <td>49.565262</td>\n",
       "      <td>0.429599</td>\n",
       "      <td>0.061322</td>\n",
       "      <td>560.579993</td>\n",
       "      <td>23.098321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.081877</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.865022</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.995889</td>\n",
       "      <td>0.998972</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.499829</td>\n",
       "      <td>0.500171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>392.362079</td>\n",
       "      <td>428.701456</td>\n",
       "      <td>25.188169</td>\n",
       "      <td>0.822693</td>\n",
       "      <td>455.606014</td>\n",
       "      <td>169.179104</td>\n",
       "      <td>0.524676</td>\n",
       "      <td>0.245608</td>\n",
       "      <td>439.590889</td>\n",
       "      <td>64.244246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052289</td>\n",
       "      <td>0.274225</td>\n",
       "      <td>0.048920</td>\n",
       "      <td>0.341758</td>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.063996</td>\n",
       "      <td>0.032048</td>\n",
       "      <td>0.018509</td>\n",
       "      <td>0.500086</td>\n",
       "      <td>0.500086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>334.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>876.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1082.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>368.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>467.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1387.500000</td>\n",
       "      <td>704.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>805.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5095.000000</td>\n",
       "      <td>2065.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>1526.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2336.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 291 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          1stFlrSF     2ndFlrSF    3SsnPorch  BedroomAbvGr   BsmtFinSF1  \\\n",
       "count  2919.000000  2919.000000  2919.000000   2919.000000  2919.000000   \n",
       "mean   1159.581706   336.483727     2.602261      2.860226   441.272011   \n",
       "std     392.362079   428.701456    25.188169      0.822693   455.606014   \n",
       "min     334.000000     0.000000     0.000000      0.000000     0.000000   \n",
       "25%     876.000000     0.000000     0.000000      2.000000     0.000000   \n",
       "50%    1082.000000     0.000000     0.000000      3.000000   368.000000   \n",
       "75%    1387.500000   704.000000     0.000000      3.000000   733.000000   \n",
       "max    5095.000000  2065.000000   508.000000      8.000000  5644.000000   \n",
       "\n",
       "        BsmtFinSF2  BsmtFullBath  BsmtHalfBath    BsmtUnfSF  EnclosedPorch  \\\n",
       "count  2919.000000   2919.000000   2919.000000  2919.000000    2919.000000   \n",
       "mean     49.565262      0.429599      0.061322   560.579993      23.098321   \n",
       "std     169.179104      0.524676      0.245608   439.590889      64.244246   \n",
       "min       0.000000      0.000000      0.000000     0.000000       0.000000   \n",
       "25%       0.000000      0.000000      0.000000   220.000000       0.000000   \n",
       "50%       0.000000      0.000000      0.000000   467.000000       0.000000   \n",
       "75%       0.000000      1.000000      0.000000   805.000000       0.000000   \n",
       "max    1526.000000      3.000000      2.000000  2336.000000    1012.000000   \n",
       "\n",
       "          ...             ConLw          New          Oth           WD  \\\n",
       "count     ...       2919.000000  2919.000000  2919.000000  2919.000000   \n",
       "mean      ...          0.002741     0.081877     0.002398     0.865022   \n",
       "std       ...          0.052289     0.274225     0.048920     0.341758   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     1.000000   \n",
       "50%       ...          0.000000     0.000000     0.000000     1.000000   \n",
       "75%       ...          0.000000     0.000000     0.000000     1.000000   \n",
       "max       ...          1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "              Grvl         Pave       AllPub       NoSeWa         Test  \\\n",
       "count  2919.000000  2919.000000  2919.000000  2919.000000  2919.000000   \n",
       "mean      0.004111     0.995889     0.998972     0.000343     0.499829   \n",
       "std       0.063996     0.063996     0.032048     0.018509     0.500086   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     1.000000     1.000000     0.000000     0.000000   \n",
       "50%       0.000000     1.000000     1.000000     0.000000     0.000000   \n",
       "75%       0.000000     1.000000     1.000000     0.000000     1.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             Train  \n",
       "count  2919.000000  \n",
       "mean      0.500171  \n",
       "std       0.500086  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 291 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "for each in X.columns.values:\n",
    "    X[each] = (X[each]-X[each].min())/(X[each].max()-X[each].min())\n",
    "    \n",
    "#standardize or normalize??\n",
    "#schneller mit NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.fillna(0, inplace=True)\n",
    "#Naja..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split Set (using source)\n",
    "def sync_datasets(X,y):\n",
    "    X_train = X[source==\"Train\"]\n",
    "    y_train = y[source==\"Train\"]\n",
    "    X_test= X[source==\"Test\"]\n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "X_train, y_train, X_test = sync_datasets(X,y)\n",
    "\n",
    "#X_train, X_test, y_train, y_test=train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RandomForest = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop non-corelating variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations=pd.concat([X,y], axis=1).corr()[\"SalePrice\"]\n",
    "keep_cols=(abs(correlations)>0.1) & (correlations<1)\n",
    "keep_cols=keep_cols[0:291]\n",
    "#Das muss noch anders gelöst werden\n",
    "X=X[X.columns.values[keep_cols]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Selection\n",
    "This step should help us to get on idea on the right number of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=None,\n",
       "   estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "   n_jobs=1, scoring='explained_variance', step=5, verbose=0)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfecv = RFECV(estimator=Boosting,scoring=\"explained_variance\", step=5)\n",
    "rfecv.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features 31\n"
     ]
    }
   ],
   "source": [
    "# Plot relationship #of features and performance\n",
    "plt.plot(range(1, len(rfecv.grid_scores_)+1), rfecv.grid_scores_)\n",
    "plt.xlabel(\"# of Features\")\n",
    "plt.ylabel(\"Score - Variance Explained\")\n",
    "plt.show()\n",
    "print(\"Optimal number of features {}\".format(rfecv.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select important columns\n",
    "selected_cols=X_train.columns.values[rfecv.support_]\n",
    "X_train=X_train[selected_cols]\n",
    "X_test=X_test[selected_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering: Creative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train=np.log(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models: Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Regressor\n",
    "RandomForest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "Regression=LinearRegression()\n",
    "Regression.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "SVR=SVR()\n",
    "SVR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
       "         n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "Ada=AdaBoostRegressor()\n",
    "Ada.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "Boosting=GradientBoostingRegressor()\n",
    "Boosting.fit(X=X_train,y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = [Regression, RandomForest, SVR, Ada,Boosting]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False) 0.8028212738300027\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='auto', max_leaf_nodes=None,\n",
      "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "           min_samples_leaf=1, min_samples_split=2,\n",
      "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "           oob_score=False, random_state=None, verbose=0, warm_start=False) 0.8595373753125669\n",
      "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
      "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False) 0.0003828615110116895\n",
      "AdaBoostRegressor(base_estimator=None, learning_rate=1.0, loss='linear',\n",
      "         n_estimators=50, random_state=None) 0.8219415265995405\n",
      "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
      "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
      "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "             min_impurity_split=None, min_samples_leaf=1,\n",
      "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "             n_estimators=100, presort='auto', random_state=None,\n",
      "             subsample=1.0, verbose=0, warm_start=False) 0.8951255560880949\n"
     ]
    }
   ],
   "source": [
    "for each in model:\n",
    "    scores = cross_val_score(estimator=each,X=X_train, y=y_train, cv=10,scoring='explained_variance') \n",
    "    print(str(each)+\" \"+str(scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = Regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([111764.95616438, 163113.75616438, 178728.75616438, ...,\n",
       "       178276.95616438, 118339.35616438, 230112.15616438])"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverting log\n",
    "#prediction = np.exp(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing Prediction to *.csv\n",
    "submission = pd.read_csv(\"sample_submission.csv\")\n",
    "submission[\"SalePrice\"]=prediction\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learnings\n",
    "\n",
    "- Vor one-hot-enconding training und test dataset zusammen \n",
    "- What is a stratified fold?\n",
    "- Variance explained for Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "1. Submit: Just one hot-encoding and Random Forest (Default): 0.15554\n",
    "2. Submit: One hot-encoding and Random Forest (Default), RFECV: 0.15051 (2.857)\n",
    "3. Submit: Like 2, +Log Target Variable, +Fill missing values with mean instead of 0:\n",
    "4. Submit: Like 3, - Fill missing values with mean instead of 0: 0.15727\n",
    "5. Submit: Normalized, median as input, pre-selected features: 0.16282\n",
    "6. Submit: Model - Regression: 0.16721\n",
    "7. Submit: Model - Boosting:0.19108 => overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([131518.04409477, 150408.90405007, 179933.05817397, ...,\n",
       "       140911.31651799, 102626.78943427, 244981.90529338])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas\n",
    "- Engineering\n",
    " - Remove colinearity\n",
    " - Impute Median\n",
    " - Normalize\n",
    "- More Algos\n",
    "- Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
